{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9fdef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import librosa\n",
    "import os\n",
    "import subprocess, re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da051f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TST_DATA_DIR = '../../.tstdata'\n",
    "DATA_DIR = TST_DATA_DIR + '/merged'\n",
    "OUT_4SEC_DIR  = TST_DATA_DIR + '/4-second'\n",
    "OUT_AUG_DIR   = TST_DATA_DIR + '/augumented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d663f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_duration(in_path: str) -> float:\n",
    "    \"\"\"Get duration in seconds.\"\"\"\n",
    "    cmd = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"csv=p=0\", in_path]\n",
    "    out = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    try:\n",
    "        return float(out.stdout.strip())\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def measure_rms(in_path: str) -> float:\n",
    "    \"\"\"Returns RMS level (dB) of a wav file.\"\"\"\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-hide_banner\", \"-i\", in_path,\n",
    "        \"-af\", f\"highpass=f={9000},volumedetect\",\n",
    "        \"-vn\", \"-f\", \"null\", \"-\"\n",
    "    ]\n",
    "    proc = subprocess.run(cmd, stderr=subprocess.PIPE, text=True)\n",
    "    match = re.search(r\"mean_volume:\\s*(-?\\d+\\.\\d+)\", proc.stderr)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return -25.0  # fa\n",
    "\n",
    "def ffmpeg_pad_recording(in_path:str, out_path:str, time=4):\n",
    "    '''\n",
    "    This monstrosity of a command should have never seen the light of the day. \n",
    "    But hey, at least is mostly does what it should ;)\n",
    "    '''\n",
    "    # WTF_FFMPEG = f'''\n",
    "    # ffmpeg -i {in_path} -filter_complex \"[0:a]aresample=48000,pan=mono|c0=0.5*c0[a]; \\\n",
    "    #     aevalsrc=random(0):d={time}:s=48000:channel_layout=mono[noise]; \\\n",
    "    #     [noise]volume=0.02[filtered]; \\\n",
    "    #     [a][filtered]amix=inputs=2:duration=longest:dropout_transition=0,atrim=duration={time}[out]\"  -map \"[out]\" -ac 1 -ar 48000 -acodec pcm_s16le {out_path}\n",
    "    # '''\n",
    "\n",
    "    rms = measure_rms(in_path) # adjust noise to file noise level\n",
    "    volume_factor = 10 ** ((rms) / 50) * 0.02\n",
    "    # volume_factor = rms\n",
    "    volume_factor = max(0.005, min(volume_factor, 0.05))\n",
    "    \n",
    "    duration = measure_duration(in_path)\n",
    "    FADE_IN = 0.3\n",
    "    delay_ms = max(0, (duration - FADE_IN) * 1000)\n",
    "\n",
    "    WTF_FFMPEG_2 = f\"\"\"\n",
    "    ffmpeg -i \"{in_path}\" -filter_complex \"\n",
    "        [0:a]aresample=48000,pan=mono|c0=0.5*c0, afade=t=out:st={duration-0.06}:d=0.06[a];\n",
    "        aevalsrc=random(0):d={time}:s=48000:channel_layout=mono[noise];\n",
    "        [noise]volume={volume_factor},\n",
    "               afade=t=in:st=0:d={FADE_IN},\n",
    "               adelay={delay_ms}|{delay_ms}[filtered];\n",
    "        [a][filtered]amix=inputs=2:duration=longest:dropout_transition=0,\n",
    "               atrim=duration={time}[out]\n",
    "    \" -map \"[out]\" -ac 1 -ar 48000 -acodec pcm_s16le -y \"{out_path}\"\n",
    "    \"\"\"\n",
    "    os.system(WTF_FFMPEG_2)\n",
    "\n",
    "\n",
    "def pad_recordings(src_root: str, dst_root: str):\n",
    "    for current_root, dirs, files in os.walk(src_root):\n",
    "        rel_path = os.path.relpath(current_root, src_root)\n",
    "        dst_dir = os.path.join(dst_root, rel_path)\n",
    "\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "        # Process wavs\n",
    "        for f in files:\n",
    "            src_path = os.path.join(current_root, f)\n",
    "            dst_path = os.path.join(dst_dir, f)\n",
    "            ffmpeg_pad_recording(src_path, dst_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6982f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_recordings(DATA_DIR, OUT_4SEC_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dd64e0",
   "metadata": {},
   "source": [
    "# Augument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363da98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rand_prefix_recording(in_path:str, out_path:str, time=4):\n",
    "\n",
    "    rms = measure_rms(in_path) # adjust noise to file noise level\n",
    "    volume_factor = 10 ** ((rms) / 50) * 0.02\n",
    "    # volume_factor = rms\n",
    "    volume_factor = max(0.005, min(volume_factor, 0.05))\n",
    "    \n",
    "    prefix_duration = abs(random.random())\n",
    "    FADE_OUT = 0.05\n",
    "    delay_ms = max(0, (prefix_duration - FADE_OUT) * 1000)\n",
    "\n",
    "    WTF_FFMPEG_2 = f\"\"\"\n",
    "    ffmpeg -i \"{in_path}\" -filter_complex \"\n",
    "        [0:a]aresample=48000,pan=mono|c0=0.5*c0,adelay={delay_ms}|{delay_ms}[a];\n",
    "        aevalsrc=random(0):d={prefix_duration}:s=48000:channel_layout=mono[noise_pre];\n",
    "        [noise_pre]volume={volume_factor},\n",
    "               afade=t=out:st={prefix_duration-FADE_OUT}:d={FADE_OUT}[filtered_pre];\n",
    "        [filtered_pre][a]amix=inputs=2:duration=longest:dropout_transition=0,\n",
    "               atrim=duration={time}[out]\n",
    "    \" -map \"[out]\" -ac 1 -ar 48000 -acodec pcm_s16le -y \"{out_path}\"\n",
    "    \"\"\"\n",
    "    os.system(WTF_FFMPEG_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761e548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = TST_DATA_DIR + '/4-second'\n",
    "dst = TST_DATA_DIR + '/augumented'\n",
    "for current_root, dirs, files in os.walk(src):\n",
    "    rel_path = os.path.relpath(current_root, src)\n",
    "    dst_dir = os.path.join(dst, rel_path)\n",
    "\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "    # Process wavs\n",
    "    for f in files:\n",
    "        src_path = os.path.join(current_root, f)\n",
    "        dst_path = os.path.join(dst_dir, \"aug_1_\" + f)\n",
    "        rand_prefix_recording(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff6c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "\n",
    "def merge_roots(src_roots: Iterable[str], dst_root: str, conflict: str = \"rename\"):\n",
    "    \"\"\"\n",
    "    Recursively copy files from multiple source roots into a single destination root,\n",
    "    preserving relative directory structure.\n",
    "\n",
    "    conflict: \"rename\" (default) | \"overwrite\" | \"skip\"\n",
    "      - \"rename\": if a target file exists, create file_base_1.ext, _2, ...\n",
    "      - \"overwrite\": overwrite existing files\n",
    "      - \"skip\": do not copy files that would collide\n",
    "    \"\"\"\n",
    "    dst_root = Path(dst_root)\n",
    "    dst_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    copied = 0\n",
    "    skipped = 0\n",
    "    renamed = 0\n",
    "\n",
    "    for src_root in src_roots:\n",
    "        src_root = Path(src_root)\n",
    "        if not src_root.exists():\n",
    "            continue\n",
    "        for src_path in src_root.rglob('*'):\n",
    "            if src_path.is_dir():\n",
    "                continue\n",
    "            # relative path w.r.t this source root\n",
    "            rel = src_path.relative_to(src_root)\n",
    "            target_dir = dst_root.joinpath(rel.parent)\n",
    "            target_dir.mkdir(parents=True, exist_ok=True)\n",
    "            target_path = target_dir.joinpath(rel.name)\n",
    "\n",
    "            if not target_path.exists():\n",
    "                shutil.copy2(src_path, target_path)\n",
    "                copied += 1\n",
    "            else:\n",
    "                if conflict == \"overwrite\":\n",
    "                    shutil.copy2(src_path, target_path)\n",
    "                    copied += 1\n",
    "                elif conflict == \"skip\":\n",
    "                    skipped += 1\n",
    "                else:  # rename\n",
    "                    base = target_path.stem\n",
    "                    ext = target_path.suffix\n",
    "                    i = 1\n",
    "                    while True:\n",
    "                        candidate = target_dir.joinpath(f\"{base}_{i}{ext}\")\n",
    "                        if not candidate.exists():\n",
    "                            shutil.copy2(src_path, candidate)\n",
    "                            renamed += 1\n",
    "                            break\n",
    "                        i += 1\n",
    "\n",
    "    print(f\"merged {len(list(src_roots))} roots -> {dst_root}\")\n",
    "    print(f\"copied: {copied}, renamed: {renamed}, skipped: {skipped}\")\n",
    "\n",
    "\n",
    "merge_roots([TST_DATA_DIR+'/4-second', TST_DATA_DIR+'/augumented'], TST_DATA_DIR+'/dataset', conflict=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76a6801",
   "metadata": {},
   "source": [
    "# Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb990bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def split_dataset(root_dir, ratio=0.8):\n",
    "    root_dir = os.path.abspath(root_dir)\n",
    "    train_dir = os.path.join(root_dir, \"train\")\n",
    "    val_dir = os.path.join(root_dir, \"val\")\n",
    "\n",
    "    # Create output directories\n",
    "    for dir_path in [train_dir, val_dir]:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    # Iterate through label folders\n",
    "    for label in os.listdir(root_dir):\n",
    "        label_path = os.path.join(root_dir, label)\n",
    "        if not os.path.isdir(label_path) or label in (\"train\", \"val\"):\n",
    "            continue\n",
    "\n",
    "        images = [f for f in os.listdir(label_path) if os.path.isfile(os.path.join(label_path, f))]\n",
    "        random.shuffle(images)\n",
    "\n",
    "        split_point = int(len(images) * ratio)\n",
    "        train_images = images[:split_point]\n",
    "        val_images = images[split_point:]\n",
    "\n",
    "        # Make label folders in train and val dirs\n",
    "        os.makedirs(os.path.join(train_dir, label), exist_ok=True)\n",
    "        os.makedirs(os.path.join(val_dir, label), exist_ok=True)\n",
    "\n",
    "        # Move or copy files\n",
    "        for img in train_images:\n",
    "            shutil.copy2(os.path.join(label_path, img), os.path.join(train_dir, label, img))\n",
    "        for img in val_images:\n",
    "            shutil.copy2(os.path.join(label_path, img), os.path.join(val_dir, label, img))\n",
    "\n",
    "        print(f\"Label '{label}': {len(train_images)} train, {len(val_images)} val\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef81be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset(TST_DATA_DIR + '/dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
